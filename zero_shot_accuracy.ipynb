{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "python_path = ['/home/claudio/.local/lib64/python3.6/site-packages','/home/sebastian/.local/lib64/python3.6/site-packages','/home/sebastian/.local/lib/python3.6/site-packages','/home/sebastian/.local/lib/python3.6/site-packages/opencv-4.1.0-py3.6.egg/cv2',\n",
    "               '/home/sebastian/.local/lib/python3.6/site-packages/cv2','/home/sebastian/dat/onnx/onnx-tensorrt/third_party/onnx']\n",
    "sys.path.extend(python_path)\n",
    "from torchnlp.word_to_vector import FastText\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "from zero_shot_model import *\n",
    "from PIL import Image\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agrego Centers\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:1'\n",
    "\n",
    "model = ZeroshotModel.load_model(device, 'models/zeroshot_model_centers_08_sun_attributes_0.94/')\n",
    "\n",
    "embedding_matrix = get_category_embedding_matrix().to(device)\n",
    "\n",
    "\n",
    "semantic_embeddings = pd.read_pickle('sun_attributes.pkl')\n",
    "categories = semantic_embeddings.Class.values\n",
    "mask = np.isin(categories, test_categories)\n",
    "mask = np.argwhere(mask)\n",
    "\n",
    "df = pd.read_pickle('tags_onehot_corrected.pkl')\n",
    "    \n",
    "files = pd.read_pickle('good_files.pkl')[0].values\n",
    "\n",
    "df = df[df.file.isin(files)]\n",
    "    \n",
    "indices = []\n",
    "for i in range(df.shape[0]):\n",
    "    row = df.iloc[i,:-1].values\n",
    "    if np.sum(row) == 1:\n",
    "        indices.append(i)\n",
    "            \n",
    "unitag = df.iloc[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(category):\n",
    "    \n",
    "    samples = unitag[unitag[category] == 1].file.values\n",
    "    \n",
    "    #results = [0]*len(categories)\n",
    "    \n",
    "    results= {}\n",
    "    \n",
    "    \n",
    "    for i in range(samples.shape[0]):\n",
    "        \n",
    "        img = Image.open('/data/hotel_images/'+samples[i])\n",
    "        \n",
    "        img_tensor = image_transformations_with_normalization(img).repeat(1,1,1,1)\n",
    "    \n",
    "        p , _, _ = model(img_tensor.to(device))\n",
    "        \n",
    "        sum_logits = torch.zeros(p.shape[1], embedding_matrix.shape[1]).to(device)\n",
    "        for i in range(4):\n",
    "            sum_logits += torch.mm(p[i], embedding_matrix.to(device))\n",
    "\n",
    "        sum_logits = torch.nn.functional.softmax(sum_logits, dim = 1)\n",
    "\n",
    "        sum_logits = sum_logits.T[mask.ravel()].T\n",
    "\n",
    "        indices_pred = torch.topk(sum_logits, k = 1, dim = 1)[1].detach().cpu().numpy().squeeze()\n",
    "        \n",
    "        #results[indices_pred] += 1\n",
    "        \n",
    "        cat = categories[mask[indices_pred]][0]\n",
    "        \n",
    "        if cat  in results:\n",
    "            results[cat] = results[cat] + 1\n",
    "        else:\n",
    "            results[cat] = 1\n",
    "            \n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/claudio/.local/lib/python3.6/site-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    }
   ],
   "source": [
    "res_kitchen = accuracy('kitchen')\n",
    "res_health_club = accuracy('health_club')\n",
    "res_restaurant = accuracy('health_club')\n",
    "res_natural_view = accuracy('natural_view')\n",
    "\n",
    "#results = np.array([res_kitchen, res_health_club, res_restaurant, res_natural_view])\n",
    "\n",
    "#results = pd.DataFrame(data=results, index=['kitchen', 'health_club','restaurant', 'natural_view'], columns=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kitchen': 634, 'restaurant': 115, 'health_club': 27, 'natural_view': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_kitchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural_view': 1150, 'health_club': 38, 'kitchen': 16, 'restaurant': 14}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_natural_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kitchen': 243, 'natural_view': 5, 'restaurant': 73, 'health_club': 4}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kitchen': 243, 'natural_view': 5, 'restaurant': 73, 'health_club': 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_health_club"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('tags_onehot_corrected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.read_pickle('good_files.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.file.isin(files[0].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2884bcd3-73f6-4694-882d-970f309b8d15.jpg',\n",
       "       '69d44bea-3940-46f1-bf0a-a345ab5b7ca5.jpg',\n",
       "       'b04904d9-70b8-40e2-8949-fe49530461e7.jpg', ...,\n",
       "       'sun_bejyseuksiozrxjl.jpg', 'sun_aemqrnupbojbmaql.jpg',\n",
       "       'sun_dqliiydyhpnjwrfz.jpg'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34942, 32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('multitag_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
